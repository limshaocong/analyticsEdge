{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FAANG Volume Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "re0kLUG1aPQN"
      ],
      "authorship_tag": "ABX9TyNHq+Gy9SMFbADQaYNxHOLJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limshaocong/analyticsEdge/blob/main/FAANG_Volume_Prediction_caa%2024Nov21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG9fd9ROT2LV"
      },
      "source": [
        "# **Preliminaries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cALQFUXPSRWz"
      },
      "source": [
        "suppressMessages(library(tidyverse)) # generic must have package\n",
        "suppressMessages(library(dplyr))\n",
        "suppressMessages(library(ggplot2)) # plotting package\n",
        "suppressMessages(library(lubridate)) # easy comprehension of dates from string to correct datetime format\n",
        "suppressMessages(library(data.table))\n",
        "suppressMessages(library(purrr)) # reduce\n",
        "if(\"patchwork\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"patchwork\")}\n",
        "suppressMessages(library(patchwork))\n",
        "if(\"caret\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"caret\")}\n",
        "suppressMessages(library(caret))\n",
        "\n",
        "options(repr.plot.width = 10,\n",
        "        repr.plot.height = 9,\n",
        "        repr.plot.pointsize = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb4Q2CZ2T-Hl"
      },
      "source": [
        "Import data and check for any NA within the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxrUXYyWScZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0908fcdc-cfb2-4373-9b86-d1316da9f2d2"
      },
      "source": [
        "path = \"https://raw.githubusercontent.com/limshaocong/analyticsEdge/main/Datasets/FAANG/altdata.csv\"\n",
        "df = read.csv(path) %>% mutate(date = ymd(date)) %>% select(- open, - close, - high, - low)\n",
        "\n",
        "if (dim(df)[1] == dim(na.omit(df))[1]) {\n",
        "  print(\"No missing data.\")\n",
        "} else {\n",
        "  print(\"Missing data\")\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"No missing data.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nta6GvSXUg4L"
      },
      "source": [
        "# **Exploratory Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkWg0bVmUEfY"
      },
      "source": [
        "Overview of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34ebE0sfUJ26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0ab726bb-c719-4ac7-a387-88b61968a34c"
      },
      "source": [
        "head(df, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  date       ticker vol      newssentiment newsmentions twtrmentions\n",
              "1 2019-01-08 FB     26252863 63.0          2            569         \n",
              "2 2019-01-09 FB     22203279 50.0          0            489         \n",
              "3 2019-01-10 FB     16111304 50.5          2            464         \n",
              "4 2019-01-11 FB     12907031 50.0          0            368         \n",
              "5 2019-01-14 FB     20515678 50.0          0            399         \n",
              "  twtrsentiment wsbsentiment wsbmentions retailvol ⋯ twtrmentions5MA\n",
              "1 0.26889279     0.3528667   1           11163579  ⋯ 473.6          \n",
              "2 0.09406953    -0.3818000   1            9658300  ⋯ 461.0          \n",
              "3 0.17456897     0.3246000   1            6779001  ⋯ 457.8          \n",
              "4 0.17663043    -0.0799400   1            5398647  ⋯ 467.2          \n",
              "5 0.23809524    -0.1558800   1            9170878  ⋯ 462.0          \n",
              "  wsbmentions5MA newsmentions5MA twtrmentions10MA wsbmentions10MA\n",
              "1 1              0.8             487.8            1              \n",
              "2 1              0.8             473.5            1              \n",
              "3 1              0.8             469.0            1              \n",
              "4 1              0.4             487.2            1              \n",
              "5 1              0.4             495.3            1              \n",
              "  newsmentions10MA retailvollag1 retailvollag2 retailvollag4 target \n",
              "1 0.6              11163579      10410940      8964350       9658300\n",
              "2 0.4               9658300       8218650      8249882       6779001\n",
              "3 0.5               6779001       6088824      7751706       5398647\n",
              "4 0.6               5398647       7284762      7707233       9170878\n",
              "5 0.6               9170878       9325642      7777200       9480406"
            ],
            "text/latex": "A data.frame: 5 × 40\n\\begin{tabular}{r|lllllllllllllllllllll}\n  & date & ticker & vol & newssentiment & newsmentions & twtrmentions & twtrsentiment & wsbsentiment & wsbmentions & retailvol & ⋯ & twtrmentions5MA & wsbmentions5MA & newsmentions5MA & twtrmentions10MA & wsbmentions10MA & newsmentions10MA & retailvollag1 & retailvollag2 & retailvollag4 & target\\\\\n  & <date> & <chr> & <int> & <dbl> & <int> & <int> & <dbl> & <dbl> & <int> & <int> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <int>\\\\\n\\hline\n\t1 & 2019-01-08 & FB & 26252863 & 63.0 & 2 & 569 & 0.26889279 &  0.3528667 & 1 & 11163579 & ⋯ & 473.6 & 1 & 0.8 & 487.8 & 1 & 0.6 & 11163579 & 10410940 & 8964350 & 9658300\\\\\n\t2 & 2019-01-09 & FB & 22203279 & 50.0 & 0 & 489 & 0.09406953 & -0.3818000 & 1 &  9658300 & ⋯ & 461.0 & 1 & 0.8 & 473.5 & 1 & 0.4 &  9658300 &  8218650 & 8249882 & 6779001\\\\\n\t3 & 2019-01-10 & FB & 16111304 & 50.5 & 2 & 464 & 0.17456897 &  0.3246000 & 1 &  6779001 & ⋯ & 457.8 & 1 & 0.8 & 469.0 & 1 & 0.5 &  6779001 &  6088824 & 7751706 & 5398647\\\\\n\t4 & 2019-01-11 & FB & 12907031 & 50.0 & 0 & 368 & 0.17663043 & -0.0799400 & 1 &  5398647 & ⋯ & 467.2 & 1 & 0.4 & 487.2 & 1 & 0.6 &  5398647 &  7284762 & 7707233 & 9170878\\\\\n\t5 & 2019-01-14 & FB & 20515678 & 50.0 & 0 & 399 & 0.23809524 & -0.1558800 & 1 &  9170878 & ⋯ & 462.0 & 1 & 0.4 & 495.3 & 1 & 0.6 &  9170878 &  9325642 & 7777200 & 9480406\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 5 × 40\n\n| <!--/--> | date &lt;date&gt; | ticker &lt;chr&gt; | vol &lt;int&gt; | newssentiment &lt;dbl&gt; | newsmentions &lt;int&gt; | twtrmentions &lt;int&gt; | twtrsentiment &lt;dbl&gt; | wsbsentiment &lt;dbl&gt; | wsbmentions &lt;int&gt; | retailvol &lt;int&gt; | ⋯ ⋯ | twtrmentions5MA &lt;dbl&gt; | wsbmentions5MA &lt;dbl&gt; | newsmentions5MA &lt;dbl&gt; | twtrmentions10MA &lt;dbl&gt; | wsbmentions10MA &lt;dbl&gt; | newsmentions10MA &lt;dbl&gt; | retailvollag1 &lt;int&gt; | retailvollag2 &lt;dbl&gt; | retailvollag4 &lt;dbl&gt; | target &lt;int&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 2019-01-08 | FB | 26252863 | 63.0 | 2 | 569 | 0.26889279 |  0.3528667 | 1 | 11163579 | ⋯ | 473.6 | 1 | 0.8 | 487.8 | 1 | 0.6 | 11163579 | 10410940 | 8964350 | 9658300 |\n| 2 | 2019-01-09 | FB | 22203279 | 50.0 | 0 | 489 | 0.09406953 | -0.3818000 | 1 |  9658300 | ⋯ | 461.0 | 1 | 0.8 | 473.5 | 1 | 0.4 |  9658300 |  8218650 | 8249882 | 6779001 |\n| 3 | 2019-01-10 | FB | 16111304 | 50.5 | 2 | 464 | 0.17456897 |  0.3246000 | 1 |  6779001 | ⋯ | 457.8 | 1 | 0.8 | 469.0 | 1 | 0.5 |  6779001 |  6088824 | 7751706 | 5398647 |\n| 4 | 2019-01-11 | FB | 12907031 | 50.0 | 0 | 368 | 0.17663043 | -0.0799400 | 1 |  5398647 | ⋯ | 467.2 | 1 | 0.4 | 487.2 | 1 | 0.6 |  5398647 |  7284762 | 7707233 | 9170878 |\n| 5 | 2019-01-14 | FB | 20515678 | 50.0 | 0 | 399 | 0.23809524 | -0.1558800 | 1 |  9170878 | ⋯ | 462.0 | 1 | 0.4 | 495.3 | 1 | 0.6 |  9170878 |  9325642 | 7777200 | 9480406 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 5 × 40</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>date</th><th scope=col>ticker</th><th scope=col>vol</th><th scope=col>newssentiment</th><th scope=col>newsmentions</th><th scope=col>twtrmentions</th><th scope=col>twtrsentiment</th><th scope=col>wsbsentiment</th><th scope=col>wsbmentions</th><th scope=col>retailvol</th><th scope=col>⋯</th><th scope=col>twtrmentions5MA</th><th scope=col>wsbmentions5MA</th><th scope=col>newsmentions5MA</th><th scope=col>twtrmentions10MA</th><th scope=col>wsbmentions10MA</th><th scope=col>newsmentions10MA</th><th scope=col>retailvollag1</th><th scope=col>retailvollag2</th><th scope=col>retailvollag4</th><th scope=col>target</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;date&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>2019-01-08</td><td>FB</td><td>26252863</td><td>63.0</td><td>2</td><td>569</td><td>0.26889279</td><td> 0.3528667</td><td>1</td><td>11163579</td><td>⋯</td><td>473.6</td><td>1</td><td>0.8</td><td>487.8</td><td>1</td><td>0.6</td><td>11163579</td><td>10410940</td><td>8964350</td><td>9658300</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>2019-01-09</td><td>FB</td><td>22203279</td><td>50.0</td><td>0</td><td>489</td><td>0.09406953</td><td>-0.3818000</td><td>1</td><td> 9658300</td><td>⋯</td><td>461.0</td><td>1</td><td>0.8</td><td>473.5</td><td>1</td><td>0.4</td><td> 9658300</td><td> 8218650</td><td>8249882</td><td>6779001</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>2019-01-10</td><td>FB</td><td>16111304</td><td>50.5</td><td>2</td><td>464</td><td>0.17456897</td><td> 0.3246000</td><td>1</td><td> 6779001</td><td>⋯</td><td>457.8</td><td>1</td><td>0.8</td><td>469.0</td><td>1</td><td>0.5</td><td> 6779001</td><td> 6088824</td><td>7751706</td><td>5398647</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>2019-01-11</td><td>FB</td><td>12907031</td><td>50.0</td><td>0</td><td>368</td><td>0.17663043</td><td>-0.0799400</td><td>1</td><td> 5398647</td><td>⋯</td><td>467.2</td><td>1</td><td>0.4</td><td>487.2</td><td>1</td><td>0.6</td><td> 5398647</td><td> 7284762</td><td>7707233</td><td>9170878</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>2019-01-14</td><td>FB</td><td>20515678</td><td>50.0</td><td>0</td><td>399</td><td>0.23809524</td><td>-0.1558800</td><td>1</td><td> 9170878</td><td>⋯</td><td>462.0</td><td>1</td><td>0.4</td><td>495.3</td><td>1</td><td>0.6</td><td> 9170878</td><td> 9325642</td><td>7777200</td><td>9480406</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umXIuK1pa0kG",
        "outputId": "7a102e19-f85c-445a-cb2c-0e92b64f947d"
      },
      "source": [
        "str(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'data.frame':\t3310 obs. of  40 variables:\n",
            " $ date             : Date, format: \"2019-01-08\" \"2019-01-09\" ...\n",
            " $ ticker           : chr  \"FB\" \"FB\" \"FB\" \"FB\" ...\n",
            " $ vol              : int  26252863 22203279 16111304 12907031 20515678 24065513 18060414 15787914 32309412 22393694 ...\n",
            " $ newssentiment    : num  63 50 50.5 50 50 50 50 37 40 50 ...\n",
            " $ newsmentions     : int  2 0 2 0 0 0 0 1 1 0 ...\n",
            " $ twtrmentions     : int  569 489 464 368 399 616 463 476 613 496 ...\n",
            " $ twtrsentiment    : num  0.2689 0.0941 0.1746 0.1766 0.2381 ...\n",
            " $ wsbsentiment     : num  0.3529 -0.3818 0.3246 -0.0799 -0.1559 ...\n",
            " $ wsbmentions      : int  1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ retailvol        : int  11163579 9658300 6779001 5398647 9170878 9480406 7058870 5805217 11946377 8903335 ...\n",
            " $ instvol          : int  15100214 12547579 9346003 7509384 11349400 14588416 10966844 9982697 19083235 13475359 ...\n",
            " $ retailperc       : num  0.425 0.435 0.42 0.418 0.447 ...\n",
            " $ newssentimentlag1: num  50 63 50 50.5 50 50 50 50 37 40 ...\n",
            " $ newsmentionslag1 : int  0 2 0 2 0 0 0 0 1 1 ...\n",
            " $ twtrmentionslag1 : int  415 569 489 464 368 399 616 463 476 613 ...\n",
            " $ twtrsentimentlag1: num  0.2024 0.2689 0.0941 0.1746 0.1766 ...\n",
            " $ wsbsentimentlag1 : num  -0.2222 0.3529 -0.3818 0.3246 -0.0799 ...\n",
            " $ wsbmentionslag1  : int  1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ newssentimentlag2: num  50 50 63 50 50.5 50 50 50 50 37 ...\n",
            " $ newsmentionslag2 : int  0 0 2 0 2 0 0 0 0 1 ...\n",
            " $ twtrmentionslag2 : int  431 415 569 489 464 368 399 616 463 476 ...\n",
            " $ twtrsentimentlag2: num  0.058 0.2024 0.2689 0.0941 0.1746 ...\n",
            " $ wsbsentimentlag2 : num  -0.0623 -0.2222 0.3529 -0.3818 0.3246 ...\n",
            " $ wsbmentionslag2  : int  1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ newssentimentlag4: num  50 50 50 50 63 50 50.5 50 50 50 ...\n",
            " $ newsmentionslag4 : int  2 0 0 0 2 0 2 0 0 0 ...\n",
            " $ twtrmentionslag4 : int  606 521 431 415 569 489 464 368 399 616 ...\n",
            " $ twtrsentimentlag4: num  0.1172 0.0307 0.058 0.2024 0.2689 ...\n",
            " $ wsbsentimentlag4 : num  0.1815 -0.1377 -0.0623 -0.2222 0.3529 ...\n",
            " $ wsbmentionslag4  : int  1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ twtrmentions5MA  : num  474 461 458 467 462 ...\n",
            " $ wsbmentions5MA   : num  1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ newsmentions5MA  : num  0.8 0.8 0.8 0.4 0.4 0.2 0.4 0.4 0.6 1.2 ...\n",
            " $ twtrmentions10MA : num  488 474 469 487 495 ...\n",
            " $ wsbmentions10MA  : num  1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ newsmentions10MA : num  0.6 0.4 0.5 0.6 0.6 0.5 0.8 0.6 0.8 1.1 ...\n",
            " $ retailvollag1    : int  11163579 9658300 6779001 5398647 9170878 9480406 7058870 5805217 11946377 8903335 ...\n",
            " $ retailvollag2    : num  10410940 8218650 6088824 7284762 9325642 ...\n",
            " $ retailvollag4    : num  8964350 8249882 7751706 7707233 7777200 ...\n",
            " $ target           : int  9658300 6779001 5398647 9170878 9480406 7058870 5805217 11946377 8903335 7344744 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wOvv24EUY8F"
      },
      "source": [
        "662 trading days worth of training data from Jan 8, 2019 to Aug 30, 2021."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc7NYXaOUMIZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "39ba405a-81a5-4092-a68c-2c45de1265b3"
      },
      "source": [
        "df %>%\n",
        "  group_by(ticker) %>%\n",
        "  summarise(n())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ticker n()\n",
              "1 AAPL   662\n",
              "2 AMZN   662\n",
              "3 FB     662\n",
              "4 GOOGL  662\n",
              "5 NFLX   662"
            ],
            "text/latex": "A tibble: 5 × 2\n\\begin{tabular}{ll}\n ticker & n()\\\\\n <chr> & <int>\\\\\n\\hline\n\t AAPL  & 662\\\\\n\t AMZN  & 662\\\\\n\t FB    & 662\\\\\n\t GOOGL & 662\\\\\n\t NFLX  & 662\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA tibble: 5 × 2\n\n| ticker &lt;chr&gt; | n() &lt;int&gt; |\n|---|---|\n| AAPL  | 662 |\n| AMZN  | 662 |\n| FB    | 662 |\n| GOOGL | 662 |\n| NFLX  | 662 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 5 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>ticker</th><th scope=col>n()</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>AAPL </td><td>662</td></tr>\n",
              "\t<tr><td>AMZN </td><td>662</td></tr>\n",
              "\t<tr><td>FB   </td><td>662</td></tr>\n",
              "\t<tr><td>GOOGL</td><td>662</td></tr>\n",
              "\t<tr><td>NFLX </td><td>662</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re0kLUG1aPQN"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz-fVbpKbSe9"
      },
      "source": [
        "Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzUiyc3naO72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd0de144-d2ee-4aa5-8f95-5e4d89d3832d"
      },
      "source": [
        "split = as.Date(\"2020-11-24\")\n",
        "\n",
        "# Train-test split\n",
        "train = df %>% filter(date < split)\n",
        "test = df %>% filter(date >= split)\n",
        "\n",
        "train_days = dim(train)[1]/5\n",
        "test_days = dim(test)[1]/5\n",
        "\n",
        "train_prop = train_days / (train_days + test_days)\n",
        "\n",
        "paste0(\"Training data proportion: \", round(train_prop * 100, 1), \"%. Total training days = \", train_days)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"Training data proportion: 71.8%. Total training days = 475\""
            ],
            "text/latex": "'Training data proportion: 71.8\\%. Total training days = 475'",
            "text/markdown": "'Training data proportion: 71.8%. Total training days = 475'",
            "text/html": [
              "'Training data proportion: 71.8%. Total training days = 475'"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV8sndrrdZ6R"
      },
      "source": [
        "Train-validate Split - as normal k-fold CV does not work on time series, an expanding window approach is used (see Section 4.3 of https://topepo.github.io/caret/data-splitting.html#time). With these parameters, CV-error will be run on 5 different validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E00-DFtJbbxi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "b078fe7d-dc10-4311-f5c1-2677d5ba1a61"
      },
      "source": [
        "index = 1:train_days\n",
        "slices = createTimeSlices(index, initialWindow = 230, horizon = 100, fixedWindow = FALSE, skip = 28)\n",
        "\n",
        "trainslices = slices[[1]] # specific slices callable by df[trainslices[[i]],]\n",
        "testslices = slices[[2]]\n",
        "\n",
        "lapply(slices, length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "$train\n",
              "[1] 6\n",
              "\n",
              "$test\n",
              "[1] 6\n"
            ],
            "text/latex": "\\begin{description}\n\\item[\\$train] 6\n\\item[\\$test] 6\n\\end{description}\n",
            "text/markdown": "$train\n:   6\n$test\n:   6\n\n\n",
            "text/html": [
              "<dl>\n",
              "\t<dt>$train</dt>\n",
              "\t\t<dd>6</dd>\n",
              "\t<dt>$test</dt>\n",
              "\t\t<dd>6</dd>\n",
              "</dl>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60-GzaA4Qghx",
        "outputId": "93c12bad-5e3e-497c-efdc-7927e346c3f2"
      },
      "source": [
        "for (fold in 1:6) {\n",
        "  trainN = length(slices$train[[fold]])\n",
        "  testN = length(slices$test[[fold]])\n",
        "  trainperc = round(trainN / (trainN + testN), 2) * 100\n",
        "\n",
        "  print(paste0(\"Fold \", fold, \": \", trainN, \" train data. 100 test data. \", trainperc, \"%\"))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Fold 1: 230 train data. 100 test data. 70%\"\n",
            "[1] \"Fold 2: 259 train data. 100 test data. 72%\"\n",
            "[1] \"Fold 3: 288 train data. 100 test data. 74%\"\n",
            "[1] \"Fold 4: 317 train data. 100 test data. 76%\"\n",
            "[1] \"Fold 5: 346 train data. 100 test data. 78%\"\n",
            "[1] \"Fold 6: 375 train data. 100 test data. 79%\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlDdwgfEPJ8c"
      },
      "source": [
        "slices$train\n",
        "slices$test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak39HF9cf3lu"
      },
      "source": [
        "# **Model Building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmhVcrdAUa1F"
      },
      "source": [
        "## **Defining functions for various models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny598aAsf3EB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70df46ab-7862-4a9f-8143-3d2b5c4581cc"
      },
      "source": [
        "if(\"Metrics\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"Metrics\")}\n",
        "suppressMessages(library(Metrics))\n",
        "if(\"randomForest\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"randomForest\")}\n",
        "suppressMessages(library(randomForest))\n",
        "if(\"xgboost\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"xgboost\")}\n",
        "library(xgboost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkeBNAxhULSl",
        "outputId": "bc16824b-c6b9-4644-d863-a4cc45273500"
      },
      "source": [
        "install.packages(\"zoo\")\n",
        "library(zoo) # rolling mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "Attaching package: ‘zoo’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    as.Date, as.Date.numeric\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE-qeknbTmue"
      },
      "source": [
        "# Naive model using MA\n",
        "\n",
        "run_naive = function(x, MAdays) {\n",
        "\n",
        "  # Create target variable based on different MA days\n",
        "  naive = df %>%\n",
        "    group_by(ticker) %>%\n",
        "    mutate(volMA = rollmean(vol, align = \"right\", k = MAdays, fill = NA)) %>%\n",
        "    select(date, ticker, voltarget, volMA)\n",
        "\n",
        "  # Store the errors for each of the 7 folds\n",
        "  cvrmse = list()\n",
        "  cvmae = list()\n",
        "\n",
        "  for (i in 1:7) {\n",
        "    \n",
        "    validate = naive[testslices[[i]],]\n",
        "    cvrmse[i] = rmse(validate$voltarget, validate$volMA)\n",
        "    cvmae[i] = mae(validate$voltarget, validate$volMA)\n",
        "\n",
        "  # Compute aggregated statistics\n",
        "  output = list()\n",
        "  output[[\"nRMSE\"]] = mean(cvrmse)\n",
        "  output[[\"nRMSESD\"]] = sd(cvrmse)\n",
        "  output[[\"nMAE\"]] = mean(cvmae)\n",
        "  output[[\"nMAESD\"]] = sd(cvmae)\n",
        "\n",
        "  }\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN70qSkCgT_3"
      },
      "source": [
        "# Function to construct CART tree\n",
        "cart = function(trainX, trainY) {\n",
        "  \n",
        "  train_control = trainControl(method = \"timeslice\",\n",
        "                            initialWindow = 130,\n",
        "                            horizon = 30,\n",
        "                            fixedWindow = FALSE,\n",
        "                            skip = 40,\n",
        "                            savePredictions = TRUE)\n",
        "\n",
        "  # hyperparameters\n",
        "  cp_values = data.frame(.cp = seq(0, 0.02, by = 0.0001))\n",
        "\n",
        "  model = train(x = trainX,\n",
        "                y = trainY,\n",
        "                method = \"rpart\",\n",
        "                trControl = train_control,\n",
        "                tuneGrid = cp_values)\n",
        "\n",
        "}\n",
        "\n",
        "# Function to construct RandomForest\n",
        "randomforest = function(trainX, trainY) {\n",
        "\n",
        "  train_control = trainControl(method = \"timeslice\",\n",
        "                                initialWindow = 130,\n",
        "                                horizon = 30,\n",
        "                                fixedWindow = FALSE,\n",
        "                                skip = 40,\n",
        "                                savePredictions = TRUE)\n",
        "\n",
        "  # hyperparameters\n",
        "  n_pred = dim(trainX)[2]\n",
        "  mtry_low = round(0.4 * n_pred)\n",
        "  mtry_upp = round(0.6 * n_pred)\n",
        "  mtry_grid = data.frame(mtry = seq(mtry_low, mtry_upp, by = 1))\n",
        "      \n",
        "  model = train(x = trainX,\n",
        "                y = trainY,\n",
        "                method = \"rf\",\n",
        "                trControl = train_control,\n",
        "                tuneGrid = mtry_grid,\n",
        "                ntree = 300,\n",
        "                nodesize = 5)\n",
        "\n",
        "}\n",
        "\n",
        "# Function to construct XGBoost\n",
        "xgb = function(trainX, trainY) {\n",
        "  \n",
        "  train_control = trainControl(method = \"timeslice\",\n",
        "                              initialWindow = 130,\n",
        "                              horizon = 30,\n",
        "                              fixedWindow = FALSE,\n",
        "                              skip = 40,\n",
        "                              savePredictions = TRUE,\n",
        "                              allowParallel = TRUE)\n",
        "\n",
        "  # hyperparameters that require further tuning\n",
        "  parm_grid = expand.grid(nrounds = 100, \n",
        "                          max_depth = 6, \n",
        "                          eta = seq(0.01, 0.05, by = 0.001),\n",
        "                          gamma = 0,\n",
        "                          colsample_bytree = 1,\n",
        "                          min_child_weight = 1,\n",
        "                          subsample = c(0.3, 0.5))\n",
        "\n",
        "  model = train(x = trainX,\n",
        "                y = trainY,\n",
        "                method = \"xgbTree\",\n",
        "                tuneGrid = parm_grid,\n",
        "                trControl = train_control)\n",
        "\n",
        "}\n",
        "\n",
        "# Function to plot \n",
        "plotlastfold = function(model) {\n",
        "  \n",
        "  train_pred = predict(model$finalModel, newdata = trainX)\n",
        "  \n",
        "  model_df = data.frame(timesteps = seq(1, train_days), predicted = train_pred, actual = trainY)\n",
        "\n",
        "  ggplot(data = model_df, (aes(x = timesteps))) +\n",
        "    geom_line(aes(y = predicted), color = \"blue\") +\n",
        "    geom_line(aes(y = actual), color = \"black\")\n",
        "\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afgdIuqpVNNJ"
      },
      "source": [
        "# $ date             : Date, format: \"2019-01-08\" \"2019-01-09\" ...\n",
        "# $ ticker           : chr  \"FB\" \"FB\" \"FB\" \"FB\" ...\n",
        "# $ vol              : int  26252863 22203279 16111304 12907031 20515678 24065513 18060414 15787914 32309412 22393694 ...\n",
        "# $ newssentiment    : num  63 50 50.5 50 50 50 50 37 40 50 ...\n",
        "# $ newsmentions     : int  2 0 2 0 0 0 0 1 1 0 ...\n",
        "# $ twtrmentions     : int  569 489 464 368 399 616 463 476 613 496 ...\n",
        "# $ twtrsentiment    : num  0.2689 0.0941 0.1746 0.1766 0.2381 ...\n",
        "# $ wsbsentiment     : num  0.3529 -0.3818 0.3246 -0.0799 -0.1559 ...\n",
        "# $ wsbmentions      : int  1 1 1 1 1 1 1 1 1 1 ...\n",
        "# $ retailvol        : int  11163579 9658300 6779001 5398647 9170878 9480406 7058870 5805217 11946377 8903335 ...\n",
        "# $ instvol          : int  15100214 12547579 9346003 7509384 11349400 14588416 10966844 9982697 19083235 13475359 ...\n",
        "# $ retailperc       : num  0.425 0.435 0.42 0.418 0.447 ...\n",
        "# $ newssentimentlag1: num  50 63 50 50.5 50 50 50 50 37 40 ...\n",
        "# $ newsmentionslag1 : int  0 2 0 2 0 0 0 0 1 1 ...\n",
        "# $ twtrmentionslag1 : int  415 569 489 464 368 399 616 463 476 613 ...\n",
        "# $ twtrsentimentlag1: num  0.2024 0.2689 0.0941 0.1746 0.1766 ...\n",
        "# $ wsbsentimentlag1 : num  -0.2222 0.3529 -0.3818 0.3246 -0.0799 ...\n",
        "# $ wsbmentionslag1  : int  1 1 1 1 1 1 1 1 1 1 ...\n",
        "# $ newssentimentlag2: num  50 50 63 50 50.5 50 50 50 50 37 ...\n",
        "# $ newsmentionslag2 : int  0 0 2 0 2 0 0 0 0 1 ...\n",
        "# $ twtrmentionslag2 : int  431 415 569 489 464 368 399 616 463 476 ...\n",
        "# $ twtrsentimentlag2: num  0.058 0.2024 0.2689 0.0941 0.1746 ...\n",
        "# $ wsbsentimentlag2 : num  -0.0623 -0.2222 0.3529 -0.3818 0.3246 ...\n",
        "# $ wsbmentionslag2  : int  1 1 1 1 1 1 1 1 1 1 ...\n",
        "# $ newssentimentlag4: num  50 50 50 50 63 50 50.5 50 50 50 ...\n",
        "# $ newsmentionslag4 : int  2 0 0 0 2 0 2 0 0 0 ...\n",
        "# $ twtrmentionslag4 : int  606 521 431 415 569 489 464 368 399 616 ...\n",
        "# $ twtrsentimentlag4: num  0.1172 0.0307 0.058 0.2024 0.2689 ...\n",
        "# $ wsbsentimentlag4 : num  0.1815 -0.1377 -0.0623 -0.2222 0.3529 ...\n",
        "# $ wsbmentionslag4  : int  1 1 1 1 1 1 1 1 1 1 ...\n",
        "# $ twtrmentions5MA  : num  474 461 458 467 462 ...\n",
        "# $ wsbmentions5MA   : num  1 1 1 1 1 1 1 1 1 1 ...\n",
        "# $ newsmentions5MA  : num  0.8 0.8 0.8 0.4 0.4 0.2 0.4 0.4 0.6 1.2 ...\n",
        "# $ twtrmentions10MA : num  488 474 469 487 495 ...\n",
        "# $ wsbmentions10MA  : num  1 1 1 1 1 1 1 1 1 1 ...\n",
        "# $ newsmentions10MA : num  0.6 0.4 0.5 0.6 0.6 0.5 0.8 0.6 0.8 1.1 ...\n",
        "# $ retailvollag1    : int  11163579 9658300 6779001 5398647 9170878 9480406 7058870 5805217 11946377 8903335 ...\n",
        "# $ retailvollag2    : num  10410940 8218650 6088824 7284762 9325642 ...\n",
        "# $ retailvollag4    : num  8964350 8249882 7751706 7707233 7777200 ...\n",
        "# $ target           : int  9658300 6779001 5398647 9170878 9480406 7058870 5805217 11946377 8903335 7344744 ...\n",
        "\n",
        "full_feature = c(3:39)\n",
        "reduced_feature = c(3:12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "128V5xBT-qX3"
      },
      "source": [
        "run_models = function(x, feature_set) {\n",
        "\n",
        "  output = list() # initialize list to store results\n",
        "  output[[\"ticker\"]] = x # add in ticker\n",
        "\n",
        "  # Create trainX, trainY, testX and testY based on feature_set\n",
        "  trainX = train %>% filter(ticker == x) %>% select(feature_set)\n",
        "  trainY = train %>% filter(ticker == x) %>% select(c(40)) %>% pull()\n",
        "  testX = test %>% filter(ticker == x) %>% select(feature_set)\n",
        "  testY = test %>% filter(ticker == x) %>% select(c(40)) %>% pull()\n",
        "\n",
        "  # Run CART Model\n",
        "  # Extract and record error metrics\n",
        "  tree = cart(trainX, trainY)\n",
        "  output[[\"dtparams\"]] = as.list(tree$bestTune)\n",
        "  output[[\"dtRMSE\"]] = tree$results %>% arrange(RMSE) %>% dplyr::slice(1) %>% select(RMSE) %>% as.double(.)\n",
        "  output[[\"dtRMSESD\"]] = tree$results %>% arrange(RMSE) %>% dplyr::slice(1) %>% select(RMSESD) %>% as.double(.)\n",
        "  output[[\"dtMAE\"]] = tree$results %>% arrange(RMSE) %>% dplyr::slice(1) %>% select(MAE) %>% as.double(.)\n",
        "  output[[\"dtMAESD\"]] = tree$results %>% arrange(RMSE) %>% dplyr::slice(1) %>% select(MAESD) %>% as.double(.)\n",
        "  # Extract top 5 features\n",
        "\n",
        "  # Run RF Model\n",
        "  # Extract and record error metrics\n",
        "  set.seed(15071)\n",
        "  forest = randomforest(trainX, trainY)\n",
        "  output[[\"rfparams\"]] = as.list(forest$bestTune) \n",
        "  output[[\"rfRMSE\"]] = forest$results %>% arrange(RMSE) %>% dplyr::slice(1) %>% select(RMSE) %>% as.double(.)\n",
        "  output[[\"rfRMSESD\"]] = forest$results %>% arrange(RMSE) %>% dplyr::slice(1) %>% select(RMSESD) %>% as.double(.)\n",
        "  output[[\"rfMAE\"]] = forest$results %>% arrange(RMSE) %>% dplyr::slice(1) %>% select(MAE) %>% as.double(.)\n",
        "  output[[\"rfMAESD\"]] = forest$results %>% arrange(RMSE) %>% dplyr::slice(1) %>% select(MAESD) %>% as.double(.)\n",
        "  # Extract top 5 features\n",
        "\n",
        "  output = output\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5D9UwLKO8Hs"
      },
      "source": [
        "fb = run_models(\"FB\", reduced_feature)\n",
        "#aapl = run_models(\"AAPL\", reduced_feature)\n",
        "#amzn = run_models(\"AMZN\", reduced_feature)\n",
        "#nflx = run_models(\"NFLX\", reduced_feature)\n",
        "#googl = run_models(\"GOOGL\", reduced_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gujZ_ewaegka"
      },
      "source": [
        "forestImp = as.data.frame(rbind(forest$finalModel$importance)) %>% arrange(desc(IncNodePurity))\n",
        "head(forestImp, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLHe7VjxOcAv"
      },
      "source": [
        "# Construct a XGBoost\n",
        "xgboost = xgb()\n",
        "\n",
        "#xgboost$bestTune\n",
        "\n",
        "# The above parameters gives the lowest CV RMSE\n",
        "# xgBoost requires far more tuning\n",
        "# The current tuning grid is too small to explore the solution space fully\n",
        "xgboost$results %>% arrange(RMSE) %>% head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}