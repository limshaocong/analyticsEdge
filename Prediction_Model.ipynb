{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prediction Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMV7R2McG03TBQZq/BrGUrK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limshaocong/analyticsEdge/blob/main/Prediction_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MccVkK9lL0gk"
      },
      "source": [
        "# **Libraries & Data Import Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGZtp4YpTych",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e6af38-8b8d-4f89-9287-846fce916058"
      },
      "source": [
        "suppressMessages(library(tidyverse)) # generic must have package\n",
        "library(dplyr)\n",
        "library(ggplot2) # plotting package\n",
        "library(lubridate) # easy comprehension of dates from string to correct datetime format\n",
        "library(data.table)\n",
        "library(purrr) # reduce\n",
        "#if(\"caret\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"caret\")}\n",
        "#library(caret)\n",
        "#if(\"psych\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"psych\")}\n",
        "#library(psych) # unscaling\n",
        "#if(\"padr\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"padr\")}\n",
        "#library(padr)\n",
        "#if(\"janitor\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"janitor\")}\n",
        "#library(janitor)\n",
        "if(\"anytime\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"anytime\")}\n",
        "library(anytime)\n",
        "\n",
        "options(repr.plot.width = 9,\n",
        "        repr.plot.height = 6,\n",
        "        repr.plot.pointsize = 20)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘BH’\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObbT3AdLPSAK"
      },
      "source": [
        "Using the following functions to extract the daily trading data, twitter sentiment analysis, r/wsb sentiment analysis and news sentiment analysis. Thereafter, left-joining the data to daily trading data by ticker-date pairs to reduce the entire dataset down to trading days only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpQJnH0ya850"
      },
      "source": [
        "git.path = \"https://raw.githubusercontent.com/limshaocong/analyticsEdge/main/Datasets/\"\n",
        "\n",
        "# Prices\n",
        "# Source: CRSP\n",
        "\n",
        "price.path = \"CRSP_WRDS/crsp_daily_stock_price_2020.csv\"\n",
        "\n",
        "get.prices <- function(tickerlist) {\n",
        "\n",
        "  path = paste0(git.path, price.path)\n",
        "\n",
        "  df = read.csv(path) %>%\n",
        "    filter(ticker %in% tickerlist) %>%\n",
        "    #mutate(as.Date(date, format = \"%m/%d/%y\")) %>%\n",
        "    mutate(date = as.Date(date, format = \"%m/%d/%y\")) %>%\n",
        "    rename(low = BIDLO,\n",
        "          high = ASKHI,\n",
        "          open = OPENPRC,\n",
        "          close = PRC,\n",
        "          vol = VOL,\n",
        "          Ntrades = NUMTRD) %>%\n",
        "    select(ticker, date, open, close, high, low) %>%\n",
        "    mutate(change = close - open,\n",
        "          dayspread = high - low)\n",
        "}\n",
        "\n",
        "# Twitter Sentiment Analysis\n",
        "# Source: Open source\n",
        "# Scrapped by snscrape\n",
        "# Sentiment Analysis by BERT - zer0-shot, multilingual, sentiment model\n",
        "\n",
        "twtr.path = \"Imputed/twitter_sa.csv\"\n",
        "\n",
        "get.twitter.sa <- function (tickerlist){\n",
        "  path = paste0(git.path, twtr.path)\n",
        "  \n",
        "  df = read.csv(path) %>%\n",
        "    filter(ticker %in% tickerlist) %>%\n",
        "    #mutate(date = as.Date(date, format = \"%m/%d/%y\"))\n",
        "    mutate(date = anydate(date))\n",
        "\n",
        "}\n",
        "\n",
        "# r/wsb Sentiment Analysis\n",
        "# Source: Quiver Quant\n",
        "# Sentiment based on VADER sentiment\n",
        "\n",
        "wsb.path = \"Imputed/wsb_imputed_min0.csv\"\n",
        "\n",
        "get.wsb.sa <- function(tickerlist){\n",
        "\n",
        "  path = paste0(git.path, wsb.path)\n",
        "\n",
        "  df = read.csv(path) %>%\n",
        "    filter(Ticker %in% tickerlist) %>%\n",
        "    mutate(Date = mdy(Date)) %>%\n",
        "    pad(start_val = as.Date('2020-01-01'), end_val = as.Date('2020-12-31')) %>%\n",
        "    rename(wsbsentiment = Sentiment,\n",
        "          wsblog10mentions = log10Mentions) %>%\n",
        "    select(Ticker, Date, wsblog10mentions, wsbsentiment) %>%\n",
        "    rename_with(tolower) %>%\n",
        "    mutate(date = anydate(date))\n",
        "}\n",
        "\n",
        "# News Sentiment - Dow Jones + Global Press\n",
        "\n",
        "pr.path = \"Imputed/rp_imputed_min500.csv\"\n",
        "\n",
        "get.news.sa <- function(tickerlist){\n",
        "\n",
        "  path = paste0(git.path, pr.path)\n",
        "\n",
        "  df = read.csv(path) %>%\n",
        "    filter(Date >= as.Date(\"2020-01-01\") & Date <= as.Date(\"2020-12-31\")) %>%\n",
        "    filter(ticker %in% tickerlist) %>%\n",
        "    #mutate(date = as.Date(Date, format = \"%m/%d/%y\")) %>%\n",
        "    rowwise() %>%\n",
        "    mutate(newssentiment = mean(DJ_mean_ess * DJ_news_instance, PR_mean_ess * PR_news_instance)/All_news_instance) %>%\n",
        "    replace(is.na(.), 0) %>%\n",
        "    mutate(newssentiment = (newssentiment-50)/100) %>%\n",
        "    rename(newslog10mentions = log10Allmentions) %>%\n",
        "    select(ticker, Date, newssentiment, newslog10mentions) %>%\n",
        "    rename_with(tolower) %>%\n",
        "    mutate(date = anydate(date))\n",
        "}\n",
        "\n",
        "# Compile all data\n",
        "# Left join to prices df retaining only trading days\n",
        "\n",
        "get.all.data <- function(tickerlist) {\n",
        "\n",
        "  prices = get.prices(tickerlist)\n",
        "  print(\"price ok\")\n",
        "  prices$date = as.Date(prices$date)\n",
        "\n",
        "  twitter.sa = get.twitter.sa(tickerlist)\n",
        "  print(\"twtr ok\")\n",
        "  twitter.sa$date = as.Date(twitter.sa$date)\n",
        "\n",
        "  wsb.sa = get.wsb.sa(tickerlist)\n",
        "  print(\"wsb ok\")\n",
        "  wsb.sa$date = as.Date(wsb.sa$date)\n",
        "\n",
        "  news.sa = get.news.sa(tickerlist)\n",
        "  print(\"news ok\")\n",
        "  news.sa$date = as.Date(news.sa$date)\n",
        "\n",
        "  df = list(prices, wsb.sa, news.sa, twitter.sa) %>%\n",
        "            reduce(left_join, by = c(\"ticker\", \"date\"))\n",
        "}\n",
        "\n",
        "check.missing.data <- function(df) {\n",
        "  complete.row = sum(complete.cases(df))\n",
        "  actual.row = dim(df)[1]\n",
        "\n",
        "  if(complete.row == actual.row) {\n",
        "    print(\"No missing data\")\n",
        "  } else {\n",
        "    print(\"Missing data present\")\n",
        "  }\n",
        "}"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOrrajOTA0KY",
        "outputId": "b506f92b-efa3-424b-9782-ad9ec27ea183"
      },
      "source": [
        "tickerlist = list(\"UBER\", \"AMZN\", \"FB\")\n",
        "\n",
        "imported_df = get.all.data(tickerlist) %>%\n",
        "  arrange(ticker, date)\n",
        "\n",
        "ticker.count = length(unique(imported_df[[\"ticker\"]]))\n",
        "\n",
        "check.missing.data(imported_df)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"price ok\"\n",
            "[1] \"twtr ok\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message:\n",
            "“All formats failed to parse. No formats found.”\n",
            "Warning message:\n",
            "“There are NA values in the column Date. The records with NA values are returned\n",
            "in the final rows of the dataframe.”\n",
            "Warning message in min.default(structure(numeric(0), class = \"Date\"), na.rm = FALSE):\n",
            "“no non-missing arguments to min; returning Inf”\n",
            "Warning message in max.default(structure(numeric(0), class = \"Date\"), na.rm = FALSE):\n",
            "“no non-missing arguments to max; returning -Inf”\n",
            "pad applied on the interval: 365 day\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"wsb ok\"\n",
            "[1] \"news ok\"\n",
            "[1] \"Missing data present\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "brSdmbbp6COb",
        "outputId": "505fd39c-3cda-4db2-eba8-3973dff92ce7"
      },
      "source": [
        "missing_df = imported_df[rowSums(is.na(imported_df)) > 0,]\n",
        "#missing_df\n",
        "missing_df %>% pull(ticker) %>% unique()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"AMZN\" \"FB\"   \"UBER\""
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 'AMZN'\n\\item 'FB'\n\\item 'UBER'\n\\end{enumerate*}\n",
            "text/markdown": "1. 'AMZN'\n2. 'FB'\n3. 'UBER'\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'AMZN'</li><li>'FB'</li><li>'UBER'</li></ol>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POZ2u8ip_cAx"
      },
      "source": [
        "# **(Slight) Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS7NpoSl0R_-"
      },
      "source": [
        "# Add in target variable\n",
        "\n",
        "df = imported_df %>%\n",
        "  group_by(ticker) %>%\n",
        "  #mutate_at(c(3:8), scale) %>%\n",
        "  mutate(target = lead(close, n = 1, default = NA)) %>% # target using by taking the $close of the next period\n",
        "  mutate(prevclose1 = lag(close, n = 1, default = NA), # additional variables by lagging earlier $close\n",
        "         prevclose2 = lag(close, n = 2, default = NA), # in log2 scale, kaggle trick\n",
        "         prevclose4 = lag(close, n = 4, default = NA),\n",
        "         prevclose8 = lag(close, n = 8, default = NA)) %>%\n",
        "  mutate(prevwsbsentiment1 = lag(wsbsentiment, n = 1, default = NA), # additional variables by lagging earlier $wsbsentiment\n",
        "         prevwsbsentiment2 = lag(wsbsentiment, n = 2, default = NA), # in log2 scale, kaggle trick\n",
        "         prevwsbsentiment4 = lag(wsbsentiment, n = 4, default = NA),\n",
        "         prevwsbsentiment8 = lag(wsbsentiment, n = 8, default = NA)) %>%\n",
        "  mutate(prevnewssentiment1 = lag(newssentiment, n = 1, default = NA), # additional variables by lagging earlier $newssentiment\n",
        "         prevnewssentiment2 = lag(newssentiment, n = 2, default = NA), # in log2 scale, kaggle trick\n",
        "         prevnewssentiment4 = lag(newssentiment, n = 4, default = NA),\n",
        "         prevnewssentiment8 = lag(newssentiment, n = 8, default = NA)) %>%\n",
        "  mutate(prevtwtrsentiment1 = lag(twtrsentiment, n = 1, default = NA), # additional variables by lagging earlier $twtrsentiment\n",
        "         prevtwtrsentiment2 = lag(twtrsentiment, n = 2, default = NA), # in log2 scale, kaggle trick\n",
        "         prevtwtrsentiment4 = lag(twtrsentiment, n = 4, default = NA),\n",
        "         prevtwtrsentiment8 = lag(twtrsentiment, n = 8, default = NA)) %>%\n",
        "  na.omit %>%\n",
        "  as.data.frame() %>%\n",
        "  relocate(target, .after = last_col())"
      ],
      "execution_count": 440,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHztBLqs_-BZ"
      },
      "source": [
        "\"\"\"\"\n",
        "# Do scaling of all variables\n",
        "# Retain means and sd for unscaling of data\n",
        "\n",
        "scaling.mean = colMeans(df[sapply(df, is.numeric)])\n",
        "scaling.sd = sapply(df[sapply(df, is.numeric)], sd)\n",
        "\n",
        "df[map_lgl(df, is.numeric)] = df %>%\n",
        "                              select(is.numeric) %>%\n",
        "                              scale(center = scaling.mean, scale = scaling.sd)\n",
        "\"\"\""
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ_fcw8dtFDp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "e075c40d-1a06-49e1-d1f3-4086bde76856"
      },
      "source": [
        "\"\"\"\n",
        "# One-hot encoding for ticker\n",
        "\n",
        "if (ticker.count > 1){\n",
        "  dummy = dummyVars(\" ~ .\", data = df)\n",
        "  df = data.frame(predict(dummy, newdata = df))\n",
        "} \n",
        "\"\"\""
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in parse(text = x, srcfile = src): <text>:1:3: unexpected string constant\n4: if (ticker.count > 1){\n5:   dummy = dummyVars(\"\n     ^\nTraceback:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRiFPSb3V1YY"
      },
      "source": [
        "Final check for missing data before model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUC1pO6tVNvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbdfdf0-7e51-4399-ece2-19936b674239"
      },
      "source": [
        "check.missing.data(df)"
      ],
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"No missing data\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3Fxot2M_iYD"
      },
      "source": [
        "# **Train-Validate-Test Split**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Au4rwfU9cOq",
        "outputId": "a568e798-f889-4425-c32a-ed3953e096b7"
      },
      "source": [
        "split = unclass(as.Date(\"2020-09-30\"))\n",
        "\n",
        "# Train-test split\n",
        "train = df %>% filter(date < split)\n",
        "test = df %>% filter(date >= split)\n",
        "\n",
        "train.days = dim(train)[1]/ticker.count\n",
        "test.days = dim(test)[1]/ticker.count\n",
        "\n",
        "train.prop = train.days/(train.days + test.days)\n",
        "\n",
        "print(\"% of Training Data\")\n",
        "print(train.prop)\n",
        "print(train.days)"
      ],
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"% of Training Data\"\n",
            "[1] 0.7377049\n",
            "[1] 180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z4wEDjBRkzW"
      },
      "source": [
        "This splitting of train-validate only serves as an illustration. The real splitting is embedded in the training process as per normal CV. However, as normal k-fold CV does not work on time series data due to the emphasis its temporal features, a sliding window approach is used (see Section 4.3 of https://topepo.github.io/caret/data-splitting.html#time)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "N-apAr1DSvEb",
        "outputId": "33c3abad-3210-4e4a-a7aa-4c4917af0689"
      },
      "source": [
        "# In this instance, with 180 days worh of data, there are 6 folds based on the chosen parameters\n",
        "\n",
        "index = 1:train.days\n",
        "folds = createTimeSlices(index, initialWindow = 95, horizon = 30, fixedWindow = TRUE, skip = 10)\n",
        "lapply(folds, length)"
      ],
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "$train\n",
              "[1] 6\n",
              "\n",
              "$test\n",
              "[1] 6\n"
            ],
            "text/latex": "\\begin{description}\n\\item[\\$train] 6\n\\item[\\$test] 6\n\\end{description}\n",
            "text/markdown": "$train\n:   6\n$test\n:   6\n\n\n",
            "text/html": [
              "<dl>\n",
              "\t<dt>$train</dt>\n",
              "\t\t<dd>6</dd>\n",
              "\t<dt>$test</dt>\n",
              "\t\t<dd>6</dd>\n",
              "</dl>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_1RO5hYT0pJ"
      },
      "source": [
        "Sample of how the folds are constructed is as follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "W2LhX1zyvQQ1",
        "outputId": "6a798694-818f-41c8-f97f-c62d58d789a7"
      },
      "source": [
        "folds$train\n",
        "folds$test"
      ],
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "$Training095\n",
              " [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
              "[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
              "[51] 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75\n",
              "[76] 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
              "\n",
              "$Training106\n",
              " [1]  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30\n",
              "[20]  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49\n",
              "[39]  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
              "[58]  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87\n",
              "[77]  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
              "\n",
              "$Training117\n",
              " [1]  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41\n",
              "[20]  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
              "[39]  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79\n",
              "[58]  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
              "[77]  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
              "\n",
              "$Training128\n",
              " [1]  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
              "[20]  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
              "[39]  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
              "[58]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
              "[77] 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128\n",
              "\n",
              "$Training139\n",
              " [1]  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
              "[20]  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
              "[39]  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
              "[58] 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
              "[77] 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
              "\n",
              "$Training150\n",
              " [1]  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
              "[20]  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
              "[39]  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112\n",
              "[58] 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n",
              "[77] 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n"
            ],
            "text/latex": "\\begin{description}\n\\item[\\$Training095] \\begin{enumerate*}\n\\item 1\n\\item 2\n\\item 3\n\\item 4\n\\item 5\n\\item 6\n\\item 7\n\\item 8\n\\item 9\n\\item 10\n\\item 11\n\\item 12\n\\item 13\n\\item 14\n\\item 15\n\\item 16\n\\item 17\n\\item 18\n\\item 19\n\\item 20\n\\item 21\n\\item 22\n\\item 23\n\\item 24\n\\item 25\n\\item 26\n\\item 27\n\\item 28\n\\item 29\n\\item 30\n\\item 31\n\\item 32\n\\item 33\n\\item 34\n\\item 35\n\\item 36\n\\item 37\n\\item 38\n\\item 39\n\\item 40\n\\item 41\n\\item 42\n\\item 43\n\\item 44\n\\item 45\n\\item 46\n\\item 47\n\\item 48\n\\item 49\n\\item 50\n\\item 51\n\\item 52\n\\item 53\n\\item 54\n\\item 55\n\\item 56\n\\item 57\n\\item 58\n\\item 59\n\\item 60\n\\item 61\n\\item 62\n\\item 63\n\\item 64\n\\item 65\n\\item 66\n\\item 67\n\\item 68\n\\item 69\n\\item 70\n\\item 71\n\\item 72\n\\item 73\n\\item 74\n\\item 75\n\\item 76\n\\item 77\n\\item 78\n\\item 79\n\\item 80\n\\item 81\n\\item 82\n\\item 83\n\\item 84\n\\item 85\n\\item 86\n\\item 87\n\\item 88\n\\item 89\n\\item 90\n\\item 91\n\\item 92\n\\item 93\n\\item 94\n\\item 95\n\\end{enumerate*}\n\n\\item[\\$Training106] \\begin{enumerate*}\n\\item 12\n\\item 13\n\\item 14\n\\item 15\n\\item 16\n\\item 17\n\\item 18\n\\item 19\n\\item 20\n\\item 21\n\\item 22\n\\item 23\n\\item 24\n\\item 25\n\\item 26\n\\item 27\n\\item 28\n\\item 29\n\\item 30\n\\item 31\n\\item 32\n\\item 33\n\\item 34\n\\item 35\n\\item 36\n\\item 37\n\\item 38\n\\item 39\n\\item 40\n\\item 41\n\\item 42\n\\item 43\n\\item 44\n\\item 45\n\\item 46\n\\item 47\n\\item 48\n\\item 49\n\\item 50\n\\item 51\n\\item 52\n\\item 53\n\\item 54\n\\item 55\n\\item 56\n\\item 57\n\\item 58\n\\item 59\n\\item 60\n\\item 61\n\\item 62\n\\item 63\n\\item 64\n\\item 65\n\\item 66\n\\item 67\n\\item 68\n\\item 69\n\\item 70\n\\item 71\n\\item 72\n\\item 73\n\\item 74\n\\item 75\n\\item 76\n\\item 77\n\\item 78\n\\item 79\n\\item 80\n\\item 81\n\\item 82\n\\item 83\n\\item 84\n\\item 85\n\\item 86\n\\item 87\n\\item 88\n\\item 89\n\\item 90\n\\item 91\n\\item 92\n\\item 93\n\\item 94\n\\item 95\n\\item 96\n\\item 97\n\\item 98\n\\item 99\n\\item 100\n\\item 101\n\\item 102\n\\item 103\n\\item 104\n\\item 105\n\\item 106\n\\end{enumerate*}\n\n\\item[\\$Training117] \\begin{enumerate*}\n\\item 23\n\\item 24\n\\item 25\n\\item 26\n\\item 27\n\\item 28\n\\item 29\n\\item 30\n\\item 31\n\\item 32\n\\item 33\n\\item 34\n\\item 35\n\\item 36\n\\item 37\n\\item 38\n\\item 39\n\\item 40\n\\item 41\n\\item 42\n\\item 43\n\\item 44\n\\item 45\n\\item 46\n\\item 47\n\\item 48\n\\item 49\n\\item 50\n\\item 51\n\\item 52\n\\item 53\n\\item 54\n\\item 55\n\\item 56\n\\item 57\n\\item 58\n\\item 59\n\\item 60\n\\item 61\n\\item 62\n\\item 63\n\\item 64\n\\item 65\n\\item 66\n\\item 67\n\\item 68\n\\item 69\n\\item 70\n\\item 71\n\\item 72\n\\item 73\n\\item 74\n\\item 75\n\\item 76\n\\item 77\n\\item 78\n\\item 79\n\\item 80\n\\item 81\n\\item 82\n\\item 83\n\\item 84\n\\item 85\n\\item 86\n\\item 87\n\\item 88\n\\item 89\n\\item 90\n\\item 91\n\\item 92\n\\item 93\n\\item 94\n\\item 95\n\\item 96\n\\item 97\n\\item 98\n\\item 99\n\\item 100\n\\item 101\n\\item 102\n\\item 103\n\\item 104\n\\item 105\n\\item 106\n\\item 107\n\\item 108\n\\item 109\n\\item 110\n\\item 111\n\\item 112\n\\item 113\n\\item 114\n\\item 115\n\\item 116\n\\item 117\n\\end{enumerate*}\n\n\\item[\\$Training128] \\begin{enumerate*}\n\\item 34\n\\item 35\n\\item 36\n\\item 37\n\\item 38\n\\item 39\n\\item 40\n\\item 41\n\\item 42\n\\item 43\n\\item 44\n\\item 45\n\\item 46\n\\item 47\n\\item 48\n\\item 49\n\\item 50\n\\item 51\n\\item 52\n\\item 53\n\\item 54\n\\item 55\n\\item 56\n\\item 57\n\\item 58\n\\item 59\n\\item 60\n\\item 61\n\\item 62\n\\item 63\n\\item 64\n\\item 65\n\\item 66\n\\item 67\n\\item 68\n\\item 69\n\\item 70\n\\item 71\n\\item 72\n\\item 73\n\\item 74\n\\item 75\n\\item 76\n\\item 77\n\\item 78\n\\item 79\n\\item 80\n\\item 81\n\\item 82\n\\item 83\n\\item 84\n\\item 85\n\\item 86\n\\item 87\n\\item 88\n\\item 89\n\\item 90\n\\item 91\n\\item 92\n\\item 93\n\\item 94\n\\item 95\n\\item 96\n\\item 97\n\\item 98\n\\item 99\n\\item 100\n\\item 101\n\\item 102\n\\item 103\n\\item 104\n\\item 105\n\\item 106\n\\item 107\n\\item 108\n\\item 109\n\\item 110\n\\item 111\n\\item 112\n\\item 113\n\\item 114\n\\item 115\n\\item 116\n\\item 117\n\\item 118\n\\item 119\n\\item 120\n\\item 121\n\\item 122\n\\item 123\n\\item 124\n\\item 125\n\\item 126\n\\item 127\n\\item 128\n\\end{enumerate*}\n\n\\item[\\$Training139] \\begin{enumerate*}\n\\item 45\n\\item 46\n\\item 47\n\\item 48\n\\item 49\n\\item 50\n\\item 51\n\\item 52\n\\item 53\n\\item 54\n\\item 55\n\\item 56\n\\item 57\n\\item 58\n\\item 59\n\\item 60\n\\item 61\n\\item 62\n\\item 63\n\\item 64\n\\item 65\n\\item 66\n\\item 67\n\\item 68\n\\item 69\n\\item 70\n\\item 71\n\\item 72\n\\item 73\n\\item 74\n\\item 75\n\\item 76\n\\item 77\n\\item 78\n\\item 79\n\\item 80\n\\item 81\n\\item 82\n\\item 83\n\\item 84\n\\item 85\n\\item 86\n\\item 87\n\\item 88\n\\item 89\n\\item 90\n\\item 91\n\\item 92\n\\item 93\n\\item 94\n\\item 95\n\\item 96\n\\item 97\n\\item 98\n\\item 99\n\\item 100\n\\item 101\n\\item 102\n\\item 103\n\\item 104\n\\item 105\n\\item 106\n\\item 107\n\\item 108\n\\item 109\n\\item 110\n\\item 111\n\\item 112\n\\item 113\n\\item 114\n\\item 115\n\\item 116\n\\item 117\n\\item 118\n\\item 119\n\\item 120\n\\item 121\n\\item 122\n\\item 123\n\\item 124\n\\item 125\n\\item 126\n\\item 127\n\\item 128\n\\item 129\n\\item 130\n\\item 131\n\\item 132\n\\item 133\n\\item 134\n\\item 135\n\\item 136\n\\item 137\n\\item 138\n\\item 139\n\\end{enumerate*}\n\n\\item[\\$Training150] \\begin{enumerate*}\n\\item 56\n\\item 57\n\\item 58\n\\item 59\n\\item 60\n\\item 61\n\\item 62\n\\item 63\n\\item 64\n\\item 65\n\\item 66\n\\item 67\n\\item 68\n\\item 69\n\\item 70\n\\item 71\n\\item 72\n\\item 73\n\\item 74\n\\item 75\n\\item 76\n\\item 77\n\\item 78\n\\item 79\n\\item 80\n\\item 81\n\\item 82\n\\item 83\n\\item 84\n\\item 85\n\\item 86\n\\item 87\n\\item 88\n\\item 89\n\\item 90\n\\item 91\n\\item 92\n\\item 93\n\\item 94\n\\item 95\n\\item 96\n\\item 97\n\\item 98\n\\item 99\n\\item 100\n\\item 101\n\\item 102\n\\item 103\n\\item 104\n\\item 105\n\\item 106\n\\item 107\n\\item 108\n\\item 109\n\\item 110\n\\item 111\n\\item 112\n\\item 113\n\\item 114\n\\item 115\n\\item 116\n\\item 117\n\\item 118\n\\item 119\n\\item 120\n\\item 121\n\\item 122\n\\item 123\n\\item 124\n\\item 125\n\\item 126\n\\item 127\n\\item 128\n\\item 129\n\\item 130\n\\item 131\n\\item 132\n\\item 133\n\\item 134\n\\item 135\n\\item 136\n\\item 137\n\\item 138\n\\item 139\n\\item 140\n\\item 141\n\\item 142\n\\item 143\n\\item 144\n\\item 145\n\\item 146\n\\item 147\n\\item 148\n\\item 149\n\\item 150\n\\end{enumerate*}\n\n\\end{description}\n",
            "text/markdown": "$Training095\n:   1. 1\n2. 2\n3. 3\n4. 4\n5. 5\n6. 6\n7. 7\n8. 8\n9. 9\n10. 10\n11. 11\n12. 12\n13. 13\n14. 14\n15. 15\n16. 16\n17. 17\n18. 18\n19. 19\n20. 20\n21. 21\n22. 22\n23. 23\n24. 24\n25. 25\n26. 26\n27. 27\n28. 28\n29. 29\n30. 30\n31. 31\n32. 32\n33. 33\n34. 34\n35. 35\n36. 36\n37. 37\n38. 38\n39. 39\n40. 40\n41. 41\n42. 42\n43. 43\n44. 44\n45. 45\n46. 46\n47. 47\n48. 48\n49. 49\n50. 50\n51. 51\n52. 52\n53. 53\n54. 54\n55. 55\n56. 56\n57. 57\n58. 58\n59. 59\n60. 60\n61. 61\n62. 62\n63. 63\n64. 64\n65. 65\n66. 66\n67. 67\n68. 68\n69. 69\n70. 70\n71. 71\n72. 72\n73. 73\n74. 74\n75. 75\n76. 76\n77. 77\n78. 78\n79. 79\n80. 80\n81. 81\n82. 82\n83. 83\n84. 84\n85. 85\n86. 86\n87. 87\n88. 88\n89. 89\n90. 90\n91. 91\n92. 92\n93. 93\n94. 94\n95. 95\n\n\n\n$Training106\n:   1. 12\n2. 13\n3. 14\n4. 15\n5. 16\n6. 17\n7. 18\n8. 19\n9. 20\n10. 21\n11. 22\n12. 23\n13. 24\n14. 25\n15. 26\n16. 27\n17. 28\n18. 29\n19. 30\n20. 31\n21. 32\n22. 33\n23. 34\n24. 35\n25. 36\n26. 37\n27. 38\n28. 39\n29. 40\n30. 41\n31. 42\n32. 43\n33. 44\n34. 45\n35. 46\n36. 47\n37. 48\n38. 49\n39. 50\n40. 51\n41. 52\n42. 53\n43. 54\n44. 55\n45. 56\n46. 57\n47. 58\n48. 59\n49. 60\n50. 61\n51. 62\n52. 63\n53. 64\n54. 65\n55. 66\n56. 67\n57. 68\n58. 69\n59. 70\n60. 71\n61. 72\n62. 73\n63. 74\n64. 75\n65. 76\n66. 77\n67. 78\n68. 79\n69. 80\n70. 81\n71. 82\n72. 83\n73. 84\n74. 85\n75. 86\n76. 87\n77. 88\n78. 89\n79. 90\n80. 91\n81. 92\n82. 93\n83. 94\n84. 95\n85. 96\n86. 97\n87. 98\n88. 99\n89. 100\n90. 101\n91. 102\n92. 103\n93. 104\n94. 105\n95. 106\n\n\n\n$Training117\n:   1. 23\n2. 24\n3. 25\n4. 26\n5. 27\n6. 28\n7. 29\n8. 30\n9. 31\n10. 32\n11. 33\n12. 34\n13. 35\n14. 36\n15. 37\n16. 38\n17. 39\n18. 40\n19. 41\n20. 42\n21. 43\n22. 44\n23. 45\n24. 46\n25. 47\n26. 48\n27. 49\n28. 50\n29. 51\n30. 52\n31. 53\n32. 54\n33. 55\n34. 56\n35. 57\n36. 58\n37. 59\n38. 60\n39. 61\n40. 62\n41. 63\n42. 64\n43. 65\n44. 66\n45. 67\n46. 68\n47. 69\n48. 70\n49. 71\n50. 72\n51. 73\n52. 74\n53. 75\n54. 76\n55. 77\n56. 78\n57. 79\n58. 80\n59. 81\n60. 82\n61. 83\n62. 84\n63. 85\n64. 86\n65. 87\n66. 88\n67. 89\n68. 90\n69. 91\n70. 92\n71. 93\n72. 94\n73. 95\n74. 96\n75. 97\n76. 98\n77. 99\n78. 100\n79. 101\n80. 102\n81. 103\n82. 104\n83. 105\n84. 106\n85. 107\n86. 108\n87. 109\n88. 110\n89. 111\n90. 112\n91. 113\n92. 114\n93. 115\n94. 116\n95. 117\n\n\n\n$Training128\n:   1. 34\n2. 35\n3. 36\n4. 37\n5. 38\n6. 39\n7. 40\n8. 41\n9. 42\n10. 43\n11. 44\n12. 45\n13. 46\n14. 47\n15. 48\n16. 49\n17. 50\n18. 51\n19. 52\n20. 53\n21. 54\n22. 55\n23. 56\n24. 57\n25. 58\n26. 59\n27. 60\n28. 61\n29. 62\n30. 63\n31. 64\n32. 65\n33. 66\n34. 67\n35. 68\n36. 69\n37. 70\n38. 71\n39. 72\n40. 73\n41. 74\n42. 75\n43. 76\n44. 77\n45. 78\n46. 79\n47. 80\n48. 81\n49. 82\n50. 83\n51. 84\n52. 85\n53. 86\n54. 87\n55. 88\n56. 89\n57. 90\n58. 91\n59. 92\n60. 93\n61. 94\n62. 95\n63. 96\n64. 97\n65. 98\n66. 99\n67. 100\n68. 101\n69. 102\n70. 103\n71. 104\n72. 105\n73. 106\n74. 107\n75. 108\n76. 109\n77. 110\n78. 111\n79. 112\n80. 113\n81. 114\n82. 115\n83. 116\n84. 117\n85. 118\n86. 119\n87. 120\n88. 121\n89. 122\n90. 123\n91. 124\n92. 125\n93. 126\n94. 127\n95. 128\n\n\n\n$Training139\n:   1. 45\n2. 46\n3. 47\n4. 48\n5. 49\n6. 50\n7. 51\n8. 52\n9. 53\n10. 54\n11. 55\n12. 56\n13. 57\n14. 58\n15. 59\n16. 60\n17. 61\n18. 62\n19. 63\n20. 64\n21. 65\n22. 66\n23. 67\n24. 68\n25. 69\n26. 70\n27. 71\n28. 72\n29. 73\n30. 74\n31. 75\n32. 76\n33. 77\n34. 78\n35. 79\n36. 80\n37. 81\n38. 82\n39. 83\n40. 84\n41. 85\n42. 86\n43. 87\n44. 88\n45. 89\n46. 90\n47. 91\n48. 92\n49. 93\n50. 94\n51. 95\n52. 96\n53. 97\n54. 98\n55. 99\n56. 100\n57. 101\n58. 102\n59. 103\n60. 104\n61. 105\n62. 106\n63. 107\n64. 108\n65. 109\n66. 110\n67. 111\n68. 112\n69. 113\n70. 114\n71. 115\n72. 116\n73. 117\n74. 118\n75. 119\n76. 120\n77. 121\n78. 122\n79. 123\n80. 124\n81. 125\n82. 126\n83. 127\n84. 128\n85. 129\n86. 130\n87. 131\n88. 132\n89. 133\n90. 134\n91. 135\n92. 136\n93. 137\n94. 138\n95. 139\n\n\n\n$Training150\n:   1. 56\n2. 57\n3. 58\n4. 59\n5. 60\n6. 61\n7. 62\n8. 63\n9. 64\n10. 65\n11. 66\n12. 67\n13. 68\n14. 69\n15. 70\n16. 71\n17. 72\n18. 73\n19. 74\n20. 75\n21. 76\n22. 77\n23. 78\n24. 79\n25. 80\n26. 81\n27. 82\n28. 83\n29. 84\n30. 85\n31. 86\n32. 87\n33. 88\n34. 89\n35. 90\n36. 91\n37. 92\n38. 93\n39. 94\n40. 95\n41. 96\n42. 97\n43. 98\n44. 99\n45. 100\n46. 101\n47. 102\n48. 103\n49. 104\n50. 105\n51. 106\n52. 107\n53. 108\n54. 109\n55. 110\n56. 111\n57. 112\n58. 113\n59. 114\n60. 115\n61. 116\n62. 117\n63. 118\n64. 119\n65. 120\n66. 121\n67. 122\n68. 123\n69. 124\n70. 125\n71. 126\n72. 127\n73. 128\n74. 129\n75. 130\n76. 131\n77. 132\n78. 133\n79. 134\n80. 135\n81. 136\n82. 137\n83. 138\n84. 139\n85. 140\n86. 141\n87. 142\n88. 143\n89. 144\n90. 145\n91. 146\n92. 147\n93. 148\n94. 149\n95. 150\n\n\n\n\n\n",
            "text/html": [
              "<dl>\n",
              "\t<dt>$Training095</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li><li>11</li><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li><li>18</li><li>19</li><li>20</li><li>21</li><li>22</li><li>23</li><li>24</li><li>25</li><li>26</li><li>27</li><li>28</li><li>29</li><li>30</li><li>31</li><li>32</li><li>33</li><li>34</li><li>35</li><li>36</li><li>37</li><li>38</li><li>39</li><li>40</li><li>41</li><li>42</li><li>43</li><li>44</li><li>45</li><li>46</li><li>47</li><li>48</li><li>49</li><li>50</li><li>51</li><li>52</li><li>53</li><li>54</li><li>55</li><li>56</li><li>57</li><li>58</li><li>59</li><li>60</li><li>61</li><li>62</li><li>63</li><li>64</li><li>65</li><li>66</li><li>67</li><li>68</li><li>69</li><li>70</li><li>71</li><li>72</li><li>73</li><li>74</li><li>75</li><li>76</li><li>77</li><li>78</li><li>79</li><li>80</li><li>81</li><li>82</li><li>83</li><li>84</li><li>85</li><li>86</li><li>87</li><li>88</li><li>89</li><li>90</li><li>91</li><li>92</li><li>93</li><li>94</li><li>95</li></ol>\n",
              "</dd>\n",
              "\t<dt>$Training106</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>12</li><li>13</li><li>14</li><li>15</li><li>16</li><li>17</li><li>18</li><li>19</li><li>20</li><li>21</li><li>22</li><li>23</li><li>24</li><li>25</li><li>26</li><li>27</li><li>28</li><li>29</li><li>30</li><li>31</li><li>32</li><li>33</li><li>34</li><li>35</li><li>36</li><li>37</li><li>38</li><li>39</li><li>40</li><li>41</li><li>42</li><li>43</li><li>44</li><li>45</li><li>46</li><li>47</li><li>48</li><li>49</li><li>50</li><li>51</li><li>52</li><li>53</li><li>54</li><li>55</li><li>56</li><li>57</li><li>58</li><li>59</li><li>60</li><li>61</li><li>62</li><li>63</li><li>64</li><li>65</li><li>66</li><li>67</li><li>68</li><li>69</li><li>70</li><li>71</li><li>72</li><li>73</li><li>74</li><li>75</li><li>76</li><li>77</li><li>78</li><li>79</li><li>80</li><li>81</li><li>82</li><li>83</li><li>84</li><li>85</li><li>86</li><li>87</li><li>88</li><li>89</li><li>90</li><li>91</li><li>92</li><li>93</li><li>94</li><li>95</li><li>96</li><li>97</li><li>98</li><li>99</li><li>100</li><li>101</li><li>102</li><li>103</li><li>104</li><li>105</li><li>106</li></ol>\n",
              "</dd>\n",
              "\t<dt>$Training117</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>23</li><li>24</li><li>25</li><li>26</li><li>27</li><li>28</li><li>29</li><li>30</li><li>31</li><li>32</li><li>33</li><li>34</li><li>35</li><li>36</li><li>37</li><li>38</li><li>39</li><li>40</li><li>41</li><li>42</li><li>43</li><li>44</li><li>45</li><li>46</li><li>47</li><li>48</li><li>49</li><li>50</li><li>51</li><li>52</li><li>53</li><li>54</li><li>55</li><li>56</li><li>57</li><li>58</li><li>59</li><li>60</li><li>61</li><li>62</li><li>63</li><li>64</li><li>65</li><li>66</li><li>67</li><li>68</li><li>69</li><li>70</li><li>71</li><li>72</li><li>73</li><li>74</li><li>75</li><li>76</li><li>77</li><li>78</li><li>79</li><li>80</li><li>81</li><li>82</li><li>83</li><li>84</li><li>85</li><li>86</li><li>87</li><li>88</li><li>89</li><li>90</li><li>91</li><li>92</li><li>93</li><li>94</li><li>95</li><li>96</li><li>97</li><li>98</li><li>99</li><li>100</li><li>101</li><li>102</li><li>103</li><li>104</li><li>105</li><li>106</li><li>107</li><li>108</li><li>109</li><li>110</li><li>111</li><li>112</li><li>113</li><li>114</li><li>115</li><li>116</li><li>117</li></ol>\n",
              "</dd>\n",
              "\t<dt>$Training128</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>34</li><li>35</li><li>36</li><li>37</li><li>38</li><li>39</li><li>40</li><li>41</li><li>42</li><li>43</li><li>44</li><li>45</li><li>46</li><li>47</li><li>48</li><li>49</li><li>50</li><li>51</li><li>52</li><li>53</li><li>54</li><li>55</li><li>56</li><li>57</li><li>58</li><li>59</li><li>60</li><li>61</li><li>62</li><li>63</li><li>64</li><li>65</li><li>66</li><li>67</li><li>68</li><li>69</li><li>70</li><li>71</li><li>72</li><li>73</li><li>74</li><li>75</li><li>76</li><li>77</li><li>78</li><li>79</li><li>80</li><li>81</li><li>82</li><li>83</li><li>84</li><li>85</li><li>86</li><li>87</li><li>88</li><li>89</li><li>90</li><li>91</li><li>92</li><li>93</li><li>94</li><li>95</li><li>96</li><li>97</li><li>98</li><li>99</li><li>100</li><li>101</li><li>102</li><li>103</li><li>104</li><li>105</li><li>106</li><li>107</li><li>108</li><li>109</li><li>110</li><li>111</li><li>112</li><li>113</li><li>114</li><li>115</li><li>116</li><li>117</li><li>118</li><li>119</li><li>120</li><li>121</li><li>122</li><li>123</li><li>124</li><li>125</li><li>126</li><li>127</li><li>128</li></ol>\n",
              "</dd>\n",
              "\t<dt>$Training139</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>45</li><li>46</li><li>47</li><li>48</li><li>49</li><li>50</li><li>51</li><li>52</li><li>53</li><li>54</li><li>55</li><li>56</li><li>57</li><li>58</li><li>59</li><li>60</li><li>61</li><li>62</li><li>63</li><li>64</li><li>65</li><li>66</li><li>67</li><li>68</li><li>69</li><li>70</li><li>71</li><li>72</li><li>73</li><li>74</li><li>75</li><li>76</li><li>77</li><li>78</li><li>79</li><li>80</li><li>81</li><li>82</li><li>83</li><li>84</li><li>85</li><li>86</li><li>87</li><li>88</li><li>89</li><li>90</li><li>91</li><li>92</li><li>93</li><li>94</li><li>95</li><li>96</li><li>97</li><li>98</li><li>99</li><li>100</li><li>101</li><li>102</li><li>103</li><li>104</li><li>105</li><li>106</li><li>107</li><li>108</li><li>109</li><li>110</li><li>111</li><li>112</li><li>113</li><li>114</li><li>115</li><li>116</li><li>117</li><li>118</li><li>119</li><li>120</li><li>121</li><li>122</li><li>123</li><li>124</li><li>125</li><li>126</li><li>127</li><li>128</li><li>129</li><li>130</li><li>131</li><li>132</li><li>133</li><li>134</li><li>135</li><li>136</li><li>137</li><li>138</li><li>139</li></ol>\n",
              "</dd>\n",
              "\t<dt>$Training150</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>56</li><li>57</li><li>58</li><li>59</li><li>60</li><li>61</li><li>62</li><li>63</li><li>64</li><li>65</li><li>66</li><li>67</li><li>68</li><li>69</li><li>70</li><li>71</li><li>72</li><li>73</li><li>74</li><li>75</li><li>76</li><li>77</li><li>78</li><li>79</li><li>80</li><li>81</li><li>82</li><li>83</li><li>84</li><li>85</li><li>86</li><li>87</li><li>88</li><li>89</li><li>90</li><li>91</li><li>92</li><li>93</li><li>94</li><li>95</li><li>96</li><li>97</li><li>98</li><li>99</li><li>100</li><li>101</li><li>102</li><li>103</li><li>104</li><li>105</li><li>106</li><li>107</li><li>108</li><li>109</li><li>110</li><li>111</li><li>112</li><li>113</li><li>114</li><li>115</li><li>116</li><li>117</li><li>118</li><li>119</li><li>120</li><li>121</li><li>122</li><li>123</li><li>124</li><li>125</li><li>126</li><li>127</li><li>128</li><li>129</li><li>130</li><li>131</li><li>132</li><li>133</li><li>134</li><li>135</li><li>136</li><li>137</li><li>138</li><li>139</li><li>140</li><li>141</li><li>142</li><li>143</li><li>144</li><li>145</li><li>146</li><li>147</li><li>148</li><li>149</li><li>150</li></ol>\n",
              "</dd>\n",
              "</dl>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "$Testing095\n",
              " [1]  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
              "[20] 115 116 117 118 119 120 121 122 123 124 125\n",
              "\n",
              "$Testing106\n",
              " [1] 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
              "[20] 126 127 128 129 130 131 132 133 134 135 136\n",
              "\n",
              "$Testing117\n",
              " [1] 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136\n",
              "[20] 137 138 139 140 141 142 143 144 145 146 147\n",
              "\n",
              "$Testing128\n",
              " [1] 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147\n",
              "[20] 148 149 150 151 152 153 154 155 156 157 158\n",
              "\n",
              "$Testing139\n",
              " [1] 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158\n",
              "[20] 159 160 161 162 163 164 165 166 167 168 169\n",
              "\n",
              "$Testing150\n",
              " [1] 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169\n",
              "[20] 170 171 172 173 174 175 176 177 178 179 180\n"
            ],
            "text/latex": "\\begin{description}\n\\item[\\$Testing095] \\begin{enumerate*}\n\\item 96\n\\item 97\n\\item 98\n\\item 99\n\\item 100\n\\item 101\n\\item 102\n\\item 103\n\\item 104\n\\item 105\n\\item 106\n\\item 107\n\\item 108\n\\item 109\n\\item 110\n\\item 111\n\\item 112\n\\item 113\n\\item 114\n\\item 115\n\\item 116\n\\item 117\n\\item 118\n\\item 119\n\\item 120\n\\item 121\n\\item 122\n\\item 123\n\\item 124\n\\item 125\n\\end{enumerate*}\n\n\\item[\\$Testing106] \\begin{enumerate*}\n\\item 107\n\\item 108\n\\item 109\n\\item 110\n\\item 111\n\\item 112\n\\item 113\n\\item 114\n\\item 115\n\\item 116\n\\item 117\n\\item 118\n\\item 119\n\\item 120\n\\item 121\n\\item 122\n\\item 123\n\\item 124\n\\item 125\n\\item 126\n\\item 127\n\\item 128\n\\item 129\n\\item 130\n\\item 131\n\\item 132\n\\item 133\n\\item 134\n\\item 135\n\\item 136\n\\end{enumerate*}\n\n\\item[\\$Testing117] \\begin{enumerate*}\n\\item 118\n\\item 119\n\\item 120\n\\item 121\n\\item 122\n\\item 123\n\\item 124\n\\item 125\n\\item 126\n\\item 127\n\\item 128\n\\item 129\n\\item 130\n\\item 131\n\\item 132\n\\item 133\n\\item 134\n\\item 135\n\\item 136\n\\item 137\n\\item 138\n\\item 139\n\\item 140\n\\item 141\n\\item 142\n\\item 143\n\\item 144\n\\item 145\n\\item 146\n\\item 147\n\\end{enumerate*}\n\n\\item[\\$Testing128] \\begin{enumerate*}\n\\item 129\n\\item 130\n\\item 131\n\\item 132\n\\item 133\n\\item 134\n\\item 135\n\\item 136\n\\item 137\n\\item 138\n\\item 139\n\\item 140\n\\item 141\n\\item 142\n\\item 143\n\\item 144\n\\item 145\n\\item 146\n\\item 147\n\\item 148\n\\item 149\n\\item 150\n\\item 151\n\\item 152\n\\item 153\n\\item 154\n\\item 155\n\\item 156\n\\item 157\n\\item 158\n\\end{enumerate*}\n\n\\item[\\$Testing139] \\begin{enumerate*}\n\\item 140\n\\item 141\n\\item 142\n\\item 143\n\\item 144\n\\item 145\n\\item 146\n\\item 147\n\\item 148\n\\item 149\n\\item 150\n\\item 151\n\\item 152\n\\item 153\n\\item 154\n\\item 155\n\\item 156\n\\item 157\n\\item 158\n\\item 159\n\\item 160\n\\item 161\n\\item 162\n\\item 163\n\\item 164\n\\item 165\n\\item 166\n\\item 167\n\\item 168\n\\item 169\n\\end{enumerate*}\n\n\\item[\\$Testing150] \\begin{enumerate*}\n\\item 151\n\\item 152\n\\item 153\n\\item 154\n\\item 155\n\\item 156\n\\item 157\n\\item 158\n\\item 159\n\\item 160\n\\item 161\n\\item 162\n\\item 163\n\\item 164\n\\item 165\n\\item 166\n\\item 167\n\\item 168\n\\item 169\n\\item 170\n\\item 171\n\\item 172\n\\item 173\n\\item 174\n\\item 175\n\\item 176\n\\item 177\n\\item 178\n\\item 179\n\\item 180\n\\end{enumerate*}\n\n\\end{description}\n",
            "text/markdown": "$Testing095\n:   1. 96\n2. 97\n3. 98\n4. 99\n5. 100\n6. 101\n7. 102\n8. 103\n9. 104\n10. 105\n11. 106\n12. 107\n13. 108\n14. 109\n15. 110\n16. 111\n17. 112\n18. 113\n19. 114\n20. 115\n21. 116\n22. 117\n23. 118\n24. 119\n25. 120\n26. 121\n27. 122\n28. 123\n29. 124\n30. 125\n\n\n\n$Testing106\n:   1. 107\n2. 108\n3. 109\n4. 110\n5. 111\n6. 112\n7. 113\n8. 114\n9. 115\n10. 116\n11. 117\n12. 118\n13. 119\n14. 120\n15. 121\n16. 122\n17. 123\n18. 124\n19. 125\n20. 126\n21. 127\n22. 128\n23. 129\n24. 130\n25. 131\n26. 132\n27. 133\n28. 134\n29. 135\n30. 136\n\n\n\n$Testing117\n:   1. 118\n2. 119\n3. 120\n4. 121\n5. 122\n6. 123\n7. 124\n8. 125\n9. 126\n10. 127\n11. 128\n12. 129\n13. 130\n14. 131\n15. 132\n16. 133\n17. 134\n18. 135\n19. 136\n20. 137\n21. 138\n22. 139\n23. 140\n24. 141\n25. 142\n26. 143\n27. 144\n28. 145\n29. 146\n30. 147\n\n\n\n$Testing128\n:   1. 129\n2. 130\n3. 131\n4. 132\n5. 133\n6. 134\n7. 135\n8. 136\n9. 137\n10. 138\n11. 139\n12. 140\n13. 141\n14. 142\n15. 143\n16. 144\n17. 145\n18. 146\n19. 147\n20. 148\n21. 149\n22. 150\n23. 151\n24. 152\n25. 153\n26. 154\n27. 155\n28. 156\n29. 157\n30. 158\n\n\n\n$Testing139\n:   1. 140\n2. 141\n3. 142\n4. 143\n5. 144\n6. 145\n7. 146\n8. 147\n9. 148\n10. 149\n11. 150\n12. 151\n13. 152\n14. 153\n15. 154\n16. 155\n17. 156\n18. 157\n19. 158\n20. 159\n21. 160\n22. 161\n23. 162\n24. 163\n25. 164\n26. 165\n27. 166\n28. 167\n29. 168\n30. 169\n\n\n\n$Testing150\n:   1. 151\n2. 152\n3. 153\n4. 154\n5. 155\n6. 156\n7. 157\n8. 158\n9. 159\n10. 160\n11. 161\n12. 162\n13. 163\n14. 164\n15. 165\n16. 166\n17. 167\n18. 168\n19. 169\n20. 170\n21. 171\n22. 172\n23. 173\n24. 174\n25. 175\n26. 176\n27. 177\n28. 178\n29. 179\n30. 180\n\n\n\n\n\n",
            "text/html": [
              "<dl>\n",
              "\t<dt>$Testing095</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>96</li><li>97</li><li>98</li><li>99</li><li>100</li><li>101</li><li>102</li><li>103</li><li>104</li><li>105</li><li>106</li><li>107</li><li>108</li><li>109</li><li>110</li><li>111</li><li>112</li><li>113</li><li>114</li><li>115</li><li>116</li><li>117</li><li>118</li><li>119</li><li>120</li><li>121</li><li>122</li><li>123</li><li>124</li><li>125</li></ol>\n",
              "</dd>\n",
              "\t<dt>$Testing106</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>107</li><li>108</li><li>109</li><li>110</li><li>111</li><li>112</li><li>113</li><li>114</li><li>115</li><li>116</li><li>117</li><li>118</li><li>119</li><li>120</li><li>121</li><li>122</li><li>123</li><li>124</li><li>125</li><li>126</li><li>127</li><li>128</li><li>129</li><li>130</li><li>131</li><li>132</li><li>133</li><li>134</li><li>135</li><li>136</li></ol>\n",
              "</dd>\n",
              "\t<dt>$Testing117</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>118</li><li>119</li><li>120</li><li>121</li><li>122</li><li>123</li><li>124</li><li>125</li><li>126</li><li>127</li><li>128</li><li>129</li><li>130</li><li>131</li><li>132</li><li>133</li><li>134</li><li>135</li><li>136</li><li>137</li><li>138</li><li>139</li><li>140</li><li>141</li><li>142</li><li>143</li><li>144</li><li>145</li><li>146</li><li>147</li></ol>\n",
              "</dd>\n",
              "\t<dt>$Testing128</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>129</li><li>130</li><li>131</li><li>132</li><li>133</li><li>134</li><li>135</li><li>136</li><li>137</li><li>138</li><li>139</li><li>140</li><li>141</li><li>142</li><li>143</li><li>144</li><li>145</li><li>146</li><li>147</li><li>148</li><li>149</li><li>150</li><li>151</li><li>152</li><li>153</li><li>154</li><li>155</li><li>156</li><li>157</li><li>158</li></ol>\n",
              "</dd>\n",
              "\t<dt>$Testing139</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>140</li><li>141</li><li>142</li><li>143</li><li>144</li><li>145</li><li>146</li><li>147</li><li>148</li><li>149</li><li>150</li><li>151</li><li>152</li><li>153</li><li>154</li><li>155</li><li>156</li><li>157</li><li>158</li><li>159</li><li>160</li><li>161</li><li>162</li><li>163</li><li>164</li><li>165</li><li>166</li><li>167</li><li>168</li><li>169</li></ol>\n",
              "</dd>\n",
              "\t<dt>$Testing150</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>151</li><li>152</li><li>153</li><li>154</li><li>155</li><li>156</li><li>157</li><li>158</li><li>159</li><li>160</li><li>161</li><li>162</li><li>163</li><li>164</li><li>165</li><li>166</li><li>167</li><li>168</li><li>169</li><li>170</li><li>171</li><li>172</li><li>173</li><li>174</li><li>175</li><li>176</li><li>177</li><li>178</li><li>179</li><li>180</li></ol>\n",
              "</dd>\n",
              "</dl>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbh1sg88FzNq"
      },
      "source": [
        "# **Model Building and Selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2sTcfd9_w02"
      },
      "source": [
        "library(rpart)\n",
        "if(\"rpart.plot\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"rpart.plot\")}\n",
        "library(rpart.plot)\n",
        "if(\"Metrics\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"Metrics\")}\n",
        "library(Metrics)\n",
        "if(\"randomForest\" %in% rownames(installed.packages()) == FALSE) {install.packages(\"randomForest\")}\n",
        "library(randomForest)"
      ],
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G30mD-7jv80_",
        "outputId": "3a7829d3-00f0-4963-ecac-a810eb6c7a21"
      },
      "source": [
        "str(train)\n",
        "\n",
        "#3 open\n",
        "#14 twtrsentiment\n",
        "#18 prevclose8"
      ],
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'data.frame':\t180 obs. of  31 variables:\n",
            " $ ticker            : chr  \"MSFT\" \"MSFT\" \"MSFT\" \"MSFT\" ...\n",
            " $ date              : Date, format: \"2020-01-14\" \"2020-01-15\" ...\n",
            " $ open              : num  163 163 164 167 167 ...\n",
            " $ close             : num  162 163 166 167 166 ...\n",
            " $ high              : num  164 164 166 167 168 ...\n",
            " $ low               : num  162 163 164 165 166 ...\n",
            " $ change            : num  -1.26 0.56 1.82 -0.32 -0.18 ...\n",
            " $ dayspread         : num  1.88 1.37 2.21 2.04 1.76 ...\n",
            " $ wsblog10mentions  : num  1.34 1.26 1.74 2.06 1.72 ...\n",
            " $ wsbsentiment      : num  0.168395 0.123718 0.147098 0.073684 -0.000337 ...\n",
            " $ newssentiment     : num  -0.0783 0.14 0.024 -0.5 0.1475 ...\n",
            " $ newslog10mentions : num  0.845 0.699 0.778 0 0.699 ...\n",
            " $ twtrlog10mentions : num  2.53 2.44 2.64 2.73 2.49 ...\n",
            " $ twtrsentiment     : num  0.202 0.274 0.376 0.324 0.255 ...\n",
            " $ prevclose1        : num  163 162 163 166 167 ...\n",
            " $ prevclose2        : num  161 163 162 163 166 ...\n",
            " $ prevclose4        : num  160 162 161 163 162 ...\n",
            " $ prevclose8        : num  161 159 159 158 160 ...\n",
            " $ prevwsbsentiment1 : num  -0.0412 0.1684 0.1237 0.1471 0.0737 ...\n",
            " $ prevwsbsentiment2 : num  0.1533 -0.0412 0.1684 0.1237 0.1471 ...\n",
            " $ prevwsbsentiment4 : num  -0.111 0.0651 0.1533 -0.0412 0.1684 ...\n",
            " $ prevwsbsentiment8 : num  0.0582 -0.00947 -0.07072 -0.09053 -0.11102 ...\n",
            " $ prevnewssentiment1: num  -0.5 -0.0783 0.14 0.024 -0.5 ...\n",
            " $ prevnewssentiment2: num  0.0775 -0.5 -0.0783 0.14 0.024 ...\n",
            " $ prevnewssentiment4: num  0.35 0.0227 0.0775 -0.5 -0.0783 ...\n",
            " $ prevnewssentiment8: num  -0.5 -0.5 -0.5 -0.5 0.35 ...\n",
            " $ prevtwtrsentiment1: num  0.409 0.202 0.274 0.376 0.324 ...\n",
            " $ prevtwtrsentiment2: num  0.36 0.409 0.202 0.274 0.376 ...\n",
            " $ prevtwtrsentiment4: num  0.423 0.295 0.36 0.409 0.202 ...\n",
            " $ prevtwtrsentiment8: num  0.39 0.409 0.378 0.222 0.423 ...\n",
            " $ target            : num  163 166 167 166 166 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPA1ZaRI3G5E"
      },
      "source": [
        "cart <- function(trainX, trainY) {\n",
        "  \n",
        "  train.control = trainControl(method = \"timeslice\",\n",
        "                            initialWindow = 95,\n",
        "                            horizon = 30,\n",
        "                            fixedWindow = TRUE)\n",
        "\n",
        "  cp.values = data.frame(.cp = seq(0, 0.005, by = 0.0001))\n",
        "\n",
        "  model = train(x = trainX,\n",
        "                y = trainY,\n",
        "                method = \"rpart\",\n",
        "                trControl = train.control,\n",
        "                tuneGrid = cp.values)\n",
        "\n",
        "}\n",
        "\n",
        "randomforest <- function(trainX, trainY) {\n",
        "\n",
        "  train.control = trainControl(method = \"timeslice\",\n",
        "                                initialWindow = 95,\n",
        "                                horizon = 30,\n",
        "                                fixedWindow = TRUE)\n",
        "  \n",
        "  n.pred = dim(trainX)[2]\n",
        "  mtry.low = round(n.pred/3, 0) - round(n.pred/6, 0)\n",
        "  mtry.upp = mtry.low + (2 * round(n.pred/6, 0))\n",
        "  mtry.grid = data.frame(mtry = seq(mtry.low, mtry.upp, by = 1))\n",
        "      \n",
        "  model = train(x = trainX,\n",
        "                y = trainY,\n",
        "                method = \"rf\",\n",
        "                trControl = train.control,\n",
        "                tuneGrid = mtry.grid,\n",
        "                ntree = 80,\n",
        "                nodesize = 15)\n",
        "\n",
        "}"
      ],
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSn9Wu5qR0Ny",
        "outputId": "377bb222-2b28-4c52-e387-7c55e213b2e4"
      },
      "source": [
        "ticker = \"MSFT\"\n",
        "\n",
        "set.seed(15071)\n",
        "\n",
        "ticker.train = train %>% filter (ticker == ticker) %>% as.data.frame()\n",
        "trainX = ticker.train[, c(3:18)]\n",
        "trainY = ticker.train[[\"target\"]]\n",
        "\n",
        "ticker.test = test %>% filter (ticker == ticker) %>% as.data.frame()\n",
        "testX = ticker.test[, c(3:18)]\n",
        "testY = ticker.test[[\"target\"]]\n",
        "testC = ticker.test[[\"close\"]]\n",
        "\n",
        "naive.mape = smape(testC, testY)\n",
        "\n",
        "cart.mod = cart(trainX, trainY)\n",
        "\n",
        "rf.mod = randomforest(trainX, trainY)"
      ],
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
            "“There were missing values in resampled performance measures.”\n",
            "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
            "“There were missing values in resampled performance measures.”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "aH3VraNaXz6W",
        "outputId": "0873ddb5-871f-4dfb-fd16-0f10b54c69a3"
      },
      "source": [
        "naive.mape"
      ],
      "execution_count": 465,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.01206779"
            ],
            "text/latex": "0.0120677937112491",
            "text/markdown": "0.0120677937112491",
            "text/html": [
              "0.0120677937112491"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "qRk0ARF2WKxX",
        "outputId": "43d2c216-787f-4bf6-ef7b-ca768ace8439"
      },
      "source": [
        "cart.train.pred = predict(object = cart.mod$finalModel, newdata = trainX)\n",
        "cart.test.pred = predict(object = cart.mod$finalModel, newdata = testX)\n",
        "\n",
        "cart.train.mape = smape(cart.train.pred, trainY)\n",
        "cart.test.mape = smape(cart.test.pred, testY)\n",
        "\n",
        "cart.train.mape\n",
        "cart.test.mape"
      ],
      "execution_count": 467,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.01625947"
            ],
            "text/latex": "0.0162594726406018",
            "text/markdown": "0.0162594726406018",
            "text/html": [
              "0.0162594726406018"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.02341541"
            ],
            "text/latex": "0.0234154111806707",
            "text/markdown": "0.0234154111806707",
            "text/html": [
              "0.0234154111806707"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "ly4a3fPSXIu6",
        "outputId": "417c3986-d737-44ff-fd36-9dcd4201b35f"
      },
      "source": [
        "rf.train.pred = predict(object = rf.mod$finalModel, newdata = trainX)\n",
        "rf.test.pred = predict(object = rf.mod$finalModel, newdata = testX)\n",
        "\n",
        "rf.train.mape = smape(rf.train.pred, trainY)\n",
        "rf.test.mape = smape(rf.test.pred, testY)\n",
        "\n",
        "rf.train.mape\n",
        "rf.test.mape"
      ],
      "execution_count": 468,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.01236329"
            ],
            "text/latex": "0.0123632882769362",
            "text/markdown": "0.0123632882769362",
            "text/html": [
              "0.0123632882769362"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.01338314"
            ],
            "text/latex": "0.0133831392311714",
            "text/markdown": "0.0133831392311714",
            "text/html": [
              "0.0133831392311714"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  IncNodePurity\n",
              "open              10899.73195  \n",
              "close             20168.44712  \n",
              "high              13819.51287  \n",
              "low               20417.24415  \n",
              "change              161.59573  \n",
              "dayspread           132.98412  \n",
              "wsblog10mentions    127.15054  \n",
              "wsbsentiment        119.54659  \n",
              "newssentiment        58.75977  \n",
              "newslog10mentions    18.18472  \n",
              "twtrlog10mentions   101.42852  \n",
              "twtrsentiment       140.46625  \n",
              "prevclose1         7935.74643  \n",
              "prevclose2          764.29734  \n",
              "prevclose4         6452.17105  \n",
              "prevclose8          614.95180  "
            ],
            "text/latex": "A matrix: 16 × 1 of type dbl\n\\begin{tabular}{r|l}\n  & IncNodePurity\\\\\n\\hline\n\topen & 10899.73195\\\\\n\tclose & 20168.44712\\\\\n\thigh & 13819.51287\\\\\n\tlow & 20417.24415\\\\\n\tchange &   161.59573\\\\\n\tdayspread &   132.98412\\\\\n\twsblog10mentions &   127.15054\\\\\n\twsbsentiment &   119.54659\\\\\n\tnewssentiment &    58.75977\\\\\n\tnewslog10mentions &    18.18472\\\\\n\ttwtrlog10mentions &   101.42852\\\\\n\ttwtrsentiment &   140.46625\\\\\n\tprevclose1 &  7935.74643\\\\\n\tprevclose2 &   764.29734\\\\\n\tprevclose4 &  6452.17105\\\\\n\tprevclose8 &   614.95180\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA matrix: 16 × 1 of type dbl\n\n| <!--/--> | IncNodePurity |\n|---|---|\n| open | 10899.73195 |\n| close | 20168.44712 |\n| high | 13819.51287 |\n| low | 20417.24415 |\n| change |   161.59573 |\n| dayspread |   132.98412 |\n| wsblog10mentions |   127.15054 |\n| wsbsentiment |   119.54659 |\n| newssentiment |    58.75977 |\n| newslog10mentions |    18.18472 |\n| twtrlog10mentions |   101.42852 |\n| twtrsentiment |   140.46625 |\n| prevclose1 |  7935.74643 |\n| prevclose2 |   764.29734 |\n| prevclose4 |  6452.17105 |\n| prevclose8 |   614.95180 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 16 × 1 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>IncNodePurity</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>open</th><td>10899.73195</td></tr>\n",
              "\t<tr><th scope=row>close</th><td>20168.44712</td></tr>\n",
              "\t<tr><th scope=row>high</th><td>13819.51287</td></tr>\n",
              "\t<tr><th scope=row>low</th><td>20417.24415</td></tr>\n",
              "\t<tr><th scope=row>change</th><td>  161.59573</td></tr>\n",
              "\t<tr><th scope=row>dayspread</th><td>  132.98412</td></tr>\n",
              "\t<tr><th scope=row>wsblog10mentions</th><td>  127.15054</td></tr>\n",
              "\t<tr><th scope=row>wsbsentiment</th><td>  119.54659</td></tr>\n",
              "\t<tr><th scope=row>newssentiment</th><td>   58.75977</td></tr>\n",
              "\t<tr><th scope=row>newslog10mentions</th><td>   18.18472</td></tr>\n",
              "\t<tr><th scope=row>twtrlog10mentions</th><td>  101.42852</td></tr>\n",
              "\t<tr><th scope=row>twtrsentiment</th><td>  140.46625</td></tr>\n",
              "\t<tr><th scope=row>prevclose1</th><td> 7935.74643</td></tr>\n",
              "\t<tr><th scope=row>prevclose2</th><td>  764.29734</td></tr>\n",
              "\t<tr><th scope=row>prevclose4</th><td> 6452.17105</td></tr>\n",
              "\t<tr><th scope=row>prevclose8</th><td>  614.95180</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}